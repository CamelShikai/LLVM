/* Generated by CIL v. 1.7.3 */
/* print_CIL_Input is false */

#line 212 "/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stddef.h"
typedef unsigned long size_t;
#line 131 "/usr/include/x86_64-linux-gnu/bits/types.h"
typedef long __off_t;
#line 132 "/usr/include/x86_64-linux-gnu/bits/types.h"
typedef long __off64_t;
#line 44 "/usr/include/stdio.h"
struct _IO_FILE;
#line 44
struct _IO_FILE;
#line 144 "/usr/include/libio.h"
struct _IO_FILE;
#line 154 "/usr/include/libio.h"
typedef void _IO_lock_t;
#line 160 "/usr/include/libio.h"
struct _IO_marker {
   struct _IO_marker *_next ;
   struct _IO_FILE *_sbuf ;
   int _pos ;
};
#line 245 "/usr/include/libio.h"
struct _IO_FILE {
   int _flags ;
   char *_IO_read_ptr ;
   char *_IO_read_end ;
   char *_IO_read_base ;
   char *_IO_write_base ;
   char *_IO_write_ptr ;
   char *_IO_write_end ;
   char *_IO_buf_base ;
   char *_IO_buf_end ;
   char *_IO_save_base ;
   char *_IO_backup_base ;
   char *_IO_save_end ;
   struct _IO_marker *_markers ;
   struct _IO_FILE *_chain ;
   int _fileno ;
   int _flags2 ;
   __off_t _old_offset ;
   unsigned short _cur_column ;
   signed char _vtable_offset ;
   char _shortbuf[1] ;
   _IO_lock_t *_lock ;
   __off64_t _offset ;
   void *__pad1 ;
   void *__pad2 ;
   void *__pad3 ;
   void *__pad4 ;
   size_t __pad5 ;
   int _mode ;
   char _unused2[(15UL * sizeof(int ) - 4UL * sizeof(void *)) - sizeof(size_t )] ;
};
#line 315 "/usr/include/libio.h"
typedef struct _IO_FILE _IO_FILE;
#line 53 "svm_common.h"
struct word {
   long wnum ;
   float weight ;
};
#line 53 "svm_common.h"
typedef struct word WORD;
#line 58 "svm_common.h"
struct svector {
   WORD *words ;
   double twonorm_sq ;
   char *userdefined ;
   long kernel_id ;
   struct svector *next ;
   double factor ;
};
#line 58 "svm_common.h"
typedef struct svector SVECTOR;
#line 91 "svm_common.h"
struct doc {
   long docnum ;
   long queryid ;
   double costfactor ;
   long slackid ;
   SVECTOR *fvec ;
};
#line 91 "svm_common.h"
typedef struct doc DOC;
#line 121 "svm_common.h"
struct learn_parm {
   long type ;
   double svm_c ;
   double eps ;
   double svm_costratio ;
   double transduction_posratio ;
   long biased_hyperplane ;
   long sharedslack ;
   long svm_maxqpsize ;
   long svm_newvarsinqp ;
   long kernel_cache_size ;
   double epsilon_crit ;
   double epsilon_shrink ;
   long svm_iter_to_shrink ;
   long maxiter ;
   long remove_inconsistent ;
   long skip_final_opt_check ;
   long compute_loo ;
   double rho ;
   long xa_depth ;
   char predfile[200] ;
   char alphafile[200] ;
   double epsilon_const ;
   double epsilon_a ;
   double opt_precision ;
   long svm_c_steps ;
   double svm_c_factor ;
   double svm_costratio_unlab ;
   double svm_unlabbound ;
   double *svm_cost ;
   long totwords ;
};
#line 121 "svm_common.h"
typedef struct learn_parm LEARN_PARM;
#line 184 "svm_common.h"
struct kernel_parm {
   long kernel_type ;
   long poly_degree ;
   double rbf_gamma ;
   double coef_lin ;
   double coef_const ;
   char custom[50] ;
};
#line 184 "svm_common.h"
typedef struct kernel_parm KERNEL_PARM;
#line 193 "svm_common.h"
struct model {
   long sv_num ;
   long at_upper_bound ;
   double b ;
   DOC **supvec ;
   double *alpha ;
   long *index ;
   long totwords ;
   long totdoc ;
   KERNEL_PARM kernel_parm ;
   double loo_error ;
   double loo_recall ;
   double loo_precision ;
   double xa_error ;
   double xa_recall ;
   double xa_precision ;
   double *lin_weights ;
   double maxdiff ;
};
#line 193 "svm_common.h"
typedef struct model MODEL;
#line 223 "svm_common.h"
struct kernel_cache {
   long *index ;
   float *buffer ;
   long *invindex ;
   long *active2totdoc ;
   long *totdoc2active ;
   long *lru ;
   long *occu ;
   long elems ;
   long max_elems ;
   long time ;
   long activenum ;
   long buffsize ;
};
#line 223 "svm_common.h"
typedef struct kernel_cache KERNEL_CACHE;
#line 434 "/usr/include/libio.h"
extern int _IO_getc(_IO_FILE *__fp ) ;
#line 168 "/usr/include/stdio.h"
extern struct _IO_FILE *stdin ;
#line 362
extern int printf(char const   * __restrict  __format  , ...) ;
#line 129 "/usr/include/string.h"
extern  __attribute__((__nothrow__)) char *( __attribute__((__nonnull__(1,2), __leaf__)) strcpy)(char * __restrict  __dest ,
                                                                                                 char const   * __restrict  __src ) ;
#line 144
extern  __attribute__((__nothrow__)) int ( __attribute__((__nonnull__(1,2), __leaf__)) strcmp)(char const   *__s1 ,
                                                                                               char const   *__s2 )  __attribute__((__pure__)) ;
#line 144 "/usr/include/stdlib.h"
extern  __attribute__((__nothrow__)) double ( __attribute__((__nonnull__(1), __leaf__)) atof)(char const   *__nptr )  __attribute__((__pure__)) ;
#line 150
extern  __attribute__((__nothrow__)) long ( __attribute__((__nonnull__(1), __leaf__)) atol)(char const   *__nptr )  __attribute__((__pure__)) ;
#line 483
extern  __attribute__((__nothrow__)) void ( __attribute__((__leaf__)) free)(void *__ptr ) ;
#line 543
extern  __attribute__((__nothrow__, __noreturn__)) void ( __attribute__((__leaf__)) exit)(int __status ) ;
#line 280 "svm_common.h"
extern void free_example(DOC * , long  ) ;
#line 283
extern void free_model(MODEL * , int  ) ;
#line 284
extern void read_documents(char * , DOC *** , double ** , long * , long * ) ;
#line 286
extern double *read_alphas(char * , long  ) ;
#line 292
extern void *my_malloc(size_t  ) ;
#line 293
extern void copyright_notice(void) ;
#line 298
extern long verbosity ;
#line 22 "svm_learn.h"
extern void svm_learn_classification(DOC ** , double * , long  , long  , LEARN_PARM * ,
                                     KERNEL_PARM * , KERNEL_CACHE * , MODEL * , double * ) ;
#line 25
extern void svm_learn_regression(DOC ** , double * , long  , long  , LEARN_PARM * ,
                                 KERNEL_PARM * , KERNEL_CACHE ** , MODEL * ) ;
#line 27
extern void svm_learn_ranking(DOC ** , double * , long  , long  , LEARN_PARM * , KERNEL_PARM * ,
                              KERNEL_CACHE ** , MODEL * ) ;
#line 29
extern void svm_learn_optimization(DOC ** , double * , long  , long  , LEARN_PARM * ,
                                   KERNEL_PARM * , KERNEL_CACHE * , MODEL * , double * ) ;
#line 115
extern KERNEL_CACHE *kernel_cache_init(long  , long  ) ;
#line 116
extern void kernel_cache_cleanup(KERNEL_CACHE * ) ;
#line 155
extern void write_model(char * , MODEL * ) ;
#line 33 "svm_learn_main.c"
char docfile[200]  ;
#line 34 "svm_learn_main.c"
char modelfile[200]  ;
#line 35 "svm_learn_main.c"
char restartfile[200]  ;
#line 37
void read_input_parameters(int argc , char **argv , char *docfile___0 , char *modelfile___0 ,
                           char *restartfile___0 , long *verbosity___0 , LEARN_PARM *learn_parm ,
                           KERNEL_PARM *kernel_parm ) ;
#line 39
void wait_any_key(void) ;
#line 40
void print_help(void) ;
void main_cil_lr_1(DOC ***__cil_ap_docs , double **__cil_ap_target , long totdoc ,
                   long i ) ;
#line 44 "svm_learn_main.c"
int main(int argc , char **argv ) 
{ 
   Pl_Start_Prolog(argc, argv);

  DOC **docs ;
  long totwords ;
  long totdoc ;
  double *target ;
  KERNEL_CACHE *kernel_cache ;
  LEARN_PARM learn_parm ;
  KERNEL_PARM kernel_parm ;
  long *__cil_pp_verbosity  = & verbosity;
  LEARN_PARM *__cil_pp_learn_parm  = & learn_parm;
  KERNEL_PARM *__cil_pp_kernel_parm  = & kernel_parm;
  DOC ***__cil_pp_docs  = & docs;
  double **__cil_pp_target  = & target;
  long *__cil_pp_totwords  = & totwords;
  long *__cil_pp_totdoc  = & totdoc;
  KERNEL_CACHE **__cil_pp_kernel_cache  = & kernel_cache;
  DOC ***__cil_fp_docs  = & docs;
  long *__cil_fp_totwords  = & totwords;
  long *__cil_fp_totdoc  = & totdoc;
  double **__cil_fp_target  = & target;
  KERNEL_CACHE **__cil_fp_kernel_cache  = & kernel_cache;
  double *alpha_in_ssa_1 ;
  void *tmp_ssa_1 ;
  MODEL *model_ssa_1 ;
  DOC **docs_ssa_1 ;
  long totwords_ssa_1 ;
  long totdoc_ssa_1 ;
  double *target_ssa_1 ;
  double *alpha_in_ssa_2 ;
  KERNEL_CACHE *kernel_cache_ssa_1 ;
  KERNEL_CACHE *kernel_cache_ssa_2 ;
  long i_ssa_1 ;
  DOC **docs_ssa_2 ;
  double *target_ssa_2 ;
  char __cil_tmp40 ;
  int __cil_tmp41 ;
  int __cil_tmp42 ;
  int __cil_tmp43 ;
  int __cil_tmp44 ;
  int __cil_tmp45 ;
  char *__cil_tmp46 ;
  char *__cil_tmp47 ;
  char *__cil_tmp48 ;
  char *__cil_tmp49 ;
  char *__cil_tmp50 ;
  long __cil_tmp51 ;
  unsigned char *__cil_tmp52 ;
  long *__cil_tmp53 ;
  long __cil_tmp54 ;
  long __cil_tmp55 ;
  long __cil_tmp56 ;
  long __cil_tmp57 ;
  long __cil_tmp58 ;
  char *__cil_tmp59 ;

  {
  {
#line 49
  alpha_in_ssa_1 = (double *)0;
#line 53
  tmp_ssa_1 = my_malloc(sizeof(MODEL ));
#line 53
  model_ssa_1 = (MODEL *)tmp_ssa_1;
#line 55
  __cil_tmp46 = docfile;
#line 55
  __cil_tmp47 = modelfile;
#line 55
  __cil_tmp48 = restartfile;
#line 55
  read_input_parameters(argc, argv, __cil_tmp46, __cil_tmp47, __cil_tmp48, __cil_pp_verbosity,
                        __cil_pp_learn_parm, __cil_pp_kernel_parm);
  *__cil_fp_docs = docs;
  *__cil_fp_totwords = totwords;
  *__cil_fp_totdoc = totdoc;
  *__cil_fp_target = target;
#line 57
  __cil_tmp49 = docfile;
#line 57
  read_documents(__cil_tmp49, __cil_pp_docs, __cil_pp_target, __cil_pp_totwords, __cil_pp_totdoc);
  docs_ssa_1 = *__cil_fp_docs;
  totwords_ssa_1 = *__cil_fp_totwords;
  totdoc_ssa_1 = *__cil_fp_totdoc;
  target_ssa_1 = *__cil_fp_target;
  }
  {
#line 58
  __cil_tmp40 = *((char *)restartfile);
#line 58
  if (__cil_tmp40) {
    {
#line 58
    __cil_tmp50 = restartfile;
#line 58
    alpha_in_ssa_2 = read_alphas(__cil_tmp50, totdoc_ssa_1);
    }
  } else {
    alpha_in_ssa_2 = alpha_in_ssa_1;
  }
  }
  {
#line 60
  __cil_tmp51 = *((long *)__cil_pp_kernel_parm);
#line 60
  __cil_tmp41 = __cil_tmp51 == 0L;
#line 60
  if (__cil_tmp41) {
    {
#line 61
    kernel_cache_ssa_1 = (KERNEL_CACHE *)0;
    }
  } else {
    {
#line 66
    __cil_tmp52 = (unsigned char *)__cil_pp_learn_parm + 72;
#line 66
    __cil_tmp53 = (long *)__cil_tmp52;
#line 66
    __cil_tmp54 = *__cil_tmp53;
#line 66
    kernel_cache_ssa_1 = kernel_cache_init(totdoc_ssa_1, __cil_tmp54);
    }
  }
  }
  {
#line 69
  __cil_tmp55 = *((long *)__cil_pp_learn_parm);
#line 69
  __cil_tmp42 = __cil_tmp55 == 1L;
#line 69
  if (__cil_tmp42) {
    {
#line 70
    svm_learn_classification(docs_ssa_1, target_ssa_1, totdoc_ssa_1, totwords_ssa_1,
                             __cil_pp_learn_parm, __cil_pp_kernel_parm, kernel_cache_ssa_1,
                             model_ssa_1, alpha_in_ssa_2);
    kernel_cache_ssa_2 = kernel_cache_ssa_1;
    }
  } else {
    {
#line 73
    __cil_tmp56 = *((long *)__cil_pp_learn_parm);
#line 73
    __cil_tmp43 = __cil_tmp56 == 2L;
#line 73
    if (__cil_tmp43) {
      {
      *__cil_fp_kernel_cache = kernel_cache_ssa_1;
#line 74
      svm_learn_regression(docs_ssa_1, target_ssa_1, totdoc_ssa_1, totwords_ssa_1,
                           __cil_pp_learn_parm, __cil_pp_kernel_parm, __cil_pp_kernel_cache,
                           model_ssa_1);
      kernel_cache_ssa_2 = *__cil_fp_kernel_cache;
      }
    } else {
      {
#line 77
      __cil_tmp57 = *((long *)__cil_pp_learn_parm);
#line 77
      __cil_tmp44 = __cil_tmp57 == 3L;
#line 77
      if (__cil_tmp44) {
        {
        *__cil_fp_kernel_cache = kernel_cache_ssa_1;
#line 78
        svm_learn_ranking(docs_ssa_1, target_ssa_1, totdoc_ssa_1, totwords_ssa_1,
                          __cil_pp_learn_parm, __cil_pp_kernel_parm, __cil_pp_kernel_cache,
                          model_ssa_1);
        kernel_cache_ssa_2 = *__cil_fp_kernel_cache;
        }
      } else {
        {
#line 81
        __cil_tmp58 = *((long *)__cil_pp_learn_parm);
#line 81
        __cil_tmp45 = __cil_tmp58 == 4L;
#line 81
        if (__cil_tmp45) {
          {
#line 82
          svm_learn_optimization(docs_ssa_1, target_ssa_1, totdoc_ssa_1, totwords_ssa_1,
                                 __cil_pp_learn_parm, __cil_pp_kernel_parm, kernel_cache_ssa_1,
                                 model_ssa_1, alpha_in_ssa_2);
          kernel_cache_ssa_2 = kernel_cache_ssa_1;
          }
        } else {
          kernel_cache_ssa_2 = kernel_cache_ssa_1;
        }
        }
      }
      }
    }
    }
  }
  }
#line 86
  if (kernel_cache_ssa_2) {
    {
#line 88
    kernel_cache_cleanup(kernel_cache_ssa_2);
    }
  } else {

  }
  {
#line 95
  __cil_tmp59 = modelfile;
#line 95
  write_model(__cil_tmp59, model_ssa_1);
#line 97
  free((void *)alpha_in_ssa_2);
#line 98
  free_model(model_ssa_1, 0);
#line 99
  i_ssa_1 = 0L;
  }
  {
  *__cil_fp_docs = docs_ssa_1;
  *__cil_fp_target = target_ssa_1;
#line 99
  main_cil_lr_1(__cil_pp_docs, __cil_pp_target, totdoc_ssa_1, i_ssa_1);
  docs_ssa_2 = *__cil_fp_docs;
  target_ssa_2 = *__cil_fp_target;
  }
  {
#line 101
  free((void *)docs_ssa_2);
#line 102
  free((void *)target_ssa_2);
  }
#line 104
  Pl_Stop_Prolog();

  return (0);
}
}
#line 109 "svm_learn_main.c"
void read_input_parameters(int argc , char **argv , char *docfile___0 , char *modelfile___0 ,
                           char *restartfile___0 , long *verbosity___0 , LEARN_PARM *learn_parm ,
                           KERNEL_PARM *kernel_parm ) 
{ 
  long i ;
  char type[100] ;
  long tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;
  int tmp___4 ;
  int tmp___5 ;

  {
#line 117
  strcpy((char */* __restrict  */)modelfile___0, (char const   */* __restrict  */)"svm_model");
#line 118
  strcpy((char */* __restrict  */)(learn_parm->predfile), (char const   */* __restrict  */)"trans_predictions");
#line 119
  strcpy((char */* __restrict  */)(learn_parm->alphafile), (char const   */* __restrict  */)"");
#line 120
  strcpy((char */* __restrict  */)restartfile___0, (char const   */* __restrict  */)"");
#line 121
  *verbosity___0 = 1L;
#line 122
  learn_parm->biased_hyperplane = 1L;
#line 123
  learn_parm->sharedslack = 0L;
#line 124
  learn_parm->remove_inconsistent = 0L;
#line 125
  learn_parm->skip_final_opt_check = 0L;
#line 126
  learn_parm->svm_maxqpsize = 10L;
#line 127
  learn_parm->svm_newvarsinqp = 0L;
#line 128
  learn_parm->svm_iter_to_shrink = -9999L;
#line 129
  learn_parm->maxiter = 100000L;
#line 130
  learn_parm->kernel_cache_size = 40L;
#line 131
  learn_parm->svm_c = 0.0;
#line 132
  learn_parm->eps = 0.1;
#line 133
  learn_parm->transduction_posratio = - 1.0;
#line 134
  learn_parm->svm_costratio = 1.0;
#line 135
  learn_parm->svm_costratio_unlab = 1.0;
#line 136
  learn_parm->svm_unlabbound = 1E-5;
#line 137
  learn_parm->epsilon_crit = 0.001;
#line 138
  learn_parm->epsilon_a = 1E-15;
#line 139
  learn_parm->compute_loo = 0L;
#line 140
  learn_parm->rho = 1.0;
#line 141
  learn_parm->xa_depth = 0L;
#line 142
  kernel_parm->kernel_type = 0L;
#line 143
  kernel_parm->poly_degree = 3L;
#line 144
  kernel_parm->rbf_gamma = 1.0;
#line 145
  kernel_parm->coef_lin = (double )1;
#line 146
  kernel_parm->coef_const = (double )1;
#line 147
  strcpy((char */* __restrict  */)(kernel_parm->custom), (char const   */* __restrict  */)"empty");
#line 148
  strcpy((char */* __restrict  */)(type), (char const   */* __restrict  */)"c");
#line 150
  i = 1L;
#line 150
  while (1) {
#line 150
    if (i < (long )argc) {
#line 150
      if (! ((int )*(*(argv + i) + 0) == 45)) {
#line 150
        break;
      }
    } else {
#line 150
      break;
    }
#line 151
    switch ((int )*(*(argv + i) + 1)) {
    case 63: 
#line 153
    print_help();
#line 153
    exit(0);
    case 122: 
#line 154
    i ++;
#line 154
    strcpy((char */* __restrict  */)(type), (char const   */* __restrict  */)*(argv + i));
#line 154
    break;
    case 118: 
#line 155
    i ++;
#line 155
    *verbosity___0 = atol((char const   *)*(argv + i));
#line 155
    break;
    case 98: 
#line 156
    i ++;
#line 156
    learn_parm->biased_hyperplane = atol((char const   *)*(argv + i));
#line 156
    break;
    case 105: 
#line 157
    i ++;
#line 157
    learn_parm->remove_inconsistent = atol((char const   *)*(argv + i));
#line 157
    break;
    case 102: 
#line 158
    i ++;
#line 158
    tmp = atol((char const   *)*(argv + i));
#line 158
    if (tmp) {
#line 158
      tmp___0 = 0;
    } else {
#line 158
      tmp___0 = 1;
    }
#line 158
    learn_parm->skip_final_opt_check = (long )tmp___0;
#line 158
    break;
    case 113: 
#line 159
    i ++;
#line 159
    learn_parm->svm_maxqpsize = atol((char const   *)*(argv + i));
#line 159
    break;
    case 110: 
#line 160
    i ++;
#line 160
    learn_parm->svm_newvarsinqp = atol((char const   *)*(argv + i));
#line 160
    break;
    case 35: 
#line 161
    i ++;
#line 161
    learn_parm->maxiter = atol((char const   *)*(argv + i));
#line 161
    break;
    case 104: 
#line 162
    i ++;
#line 162
    learn_parm->svm_iter_to_shrink = atol((char const   *)*(argv + i));
#line 162
    break;
    case 109: 
#line 163
    i ++;
#line 163
    learn_parm->kernel_cache_size = atol((char const   *)*(argv + i));
#line 163
    break;
    case 99: 
#line 164
    i ++;
#line 164
    learn_parm->svm_c = atof((char const   *)*(argv + i));
#line 164
    break;
    case 119: 
#line 165
    i ++;
#line 165
    learn_parm->eps = atof((char const   *)*(argv + i));
#line 165
    break;
    case 112: 
#line 166
    i ++;
#line 166
    learn_parm->transduction_posratio = atof((char const   *)*(argv + i));
#line 166
    break;
    case 106: 
#line 167
    i ++;
#line 167
    learn_parm->svm_costratio = atof((char const   *)*(argv + i));
#line 167
    break;
    case 101: 
#line 168
    i ++;
#line 168
    learn_parm->epsilon_crit = atof((char const   *)*(argv + i));
#line 168
    break;
    case 111: 
#line 169
    i ++;
#line 169
    learn_parm->rho = atof((char const   *)*(argv + i));
#line 169
    break;
    case 107: 
#line 170
    i ++;
#line 170
    learn_parm->xa_depth = atol((char const   *)*(argv + i));
#line 170
    break;
    case 120: 
#line 171
    i ++;
#line 171
    learn_parm->compute_loo = atol((char const   *)*(argv + i));
#line 171
    break;
    case 116: 
#line 172
    i ++;
#line 172
    kernel_parm->kernel_type = atol((char const   *)*(argv + i));
#line 172
    break;
    case 100: 
#line 173
    i ++;
#line 173
    kernel_parm->poly_degree = atol((char const   *)*(argv + i));
#line 173
    break;
    case 103: 
#line 174
    i ++;
#line 174
    kernel_parm->rbf_gamma = atof((char const   *)*(argv + i));
#line 174
    break;
    case 115: 
#line 175
    i ++;
#line 175
    kernel_parm->coef_lin = atof((char const   *)*(argv + i));
#line 175
    break;
    case 114: 
#line 176
    i ++;
#line 176
    kernel_parm->coef_const = atof((char const   *)*(argv + i));
#line 176
    break;
    case 117: 
#line 177
    i ++;
#line 177
    strcpy((char */* __restrict  */)(kernel_parm->custom), (char const   */* __restrict  */)*(argv + i));
#line 177
    break;
    case 108: 
#line 178
    i ++;
#line 178
    strcpy((char */* __restrict  */)(learn_parm->predfile), (char const   */* __restrict  */)*(argv + i));
#line 178
    break;
    case 97: 
#line 179
    i ++;
#line 179
    strcpy((char */* __restrict  */)(learn_parm->alphafile), (char const   */* __restrict  */)*(argv + i));
#line 179
    break;
    case 121: 
#line 180
    i ++;
#line 180
    strcpy((char */* __restrict  */)restartfile___0, (char const   */* __restrict  */)*(argv + i));
#line 180
    break;
    default: 
#line 181
    printf((char const   */* __restrict  */)"\nUnrecognized option %s!\n\n", *(argv + i));
#line 182
    print_help();
#line 183
    exit(0);
    }
#line 150
    i ++;
  }
#line 186
  if (i >= (long )argc) {
#line 187
    printf((char const   */* __restrict  */)"\nNot enough input parameters!\n\n");
#line 188
    wait_any_key();
#line 189
    print_help();
#line 190
    exit(0);
  }
#line 192
  strcpy((char */* __restrict  */)docfile___0, (char const   */* __restrict  */)*(argv + i));
#line 193
  if (i + 1L < (long )argc) {
#line 194
    strcpy((char */* __restrict  */)modelfile___0, (char const   */* __restrict  */)*(argv + (i + 1L)));
  }
#line 196
  if (learn_parm->svm_iter_to_shrink == -9999L) {
#line 197
    if (kernel_parm->kernel_type == 0L) {
#line 198
      learn_parm->svm_iter_to_shrink = 2L;
    } else {
#line 200
      learn_parm->svm_iter_to_shrink = 100L;
    }
  }
#line 202
  tmp___5 = strcmp((char const   *)(type), "c");
#line 202
  if (tmp___5 == 0) {
#line 203
    learn_parm->type = 1L;
  } else {
#line 205
    tmp___4 = strcmp((char const   *)(type), "r");
#line 205
    if (tmp___4 == 0) {
#line 206
      learn_parm->type = 2L;
    } else {
#line 208
      tmp___3 = strcmp((char const   *)(type), "p");
#line 208
      if (tmp___3 == 0) {
#line 209
        learn_parm->type = 3L;
      } else {
#line 211
        tmp___2 = strcmp((char const   *)(type), "o");
#line 211
        if (tmp___2 == 0) {
#line 212
          learn_parm->type = 4L;
        } else {
#line 214
          tmp___1 = strcmp((char const   *)(type), "s");
#line 214
          if (tmp___1 == 0) {
#line 215
            learn_parm->type = 4L;
#line 216
            learn_parm->sharedslack = 1L;
          } else {
#line 219
            printf((char const   */* __restrict  */)"\nUnknown type \'%s\': Valid types are \'c\' (classification), \'r\' regession, and \'p\' preference ranking.\n",
                   type);
#line 220
            wait_any_key();
#line 221
            print_help();
#line 222
            exit(0);
          }
        }
      }
    }
  }
#line 224
  if (learn_parm->skip_final_opt_check) {
#line 224
    if (kernel_parm->kernel_type == 0L) {
#line 226
      printf((char const   */* __restrict  */)"\nIt does not make sense to skip the final optimality check for linear kernels.\n\n");
#line 227
      learn_parm->skip_final_opt_check = 0L;
    }
  }
#line 229
  if (learn_parm->skip_final_opt_check) {
#line 229
    if (learn_parm->remove_inconsistent) {
#line 231
      printf((char const   */* __restrict  */)"\nIt is necessary to do the final optimality check when removing inconsistent \nexamples.\n");
#line 232
      wait_any_key();
#line 233
      print_help();
#line 234
      exit(0);
    }
  }
#line 236
  if (learn_parm->svm_maxqpsize < 2L) {
#line 237
    printf((char const   */* __restrict  */)"\nMaximum size of QP-subproblems not in valid range: %ld [2..]\n",
           learn_parm->svm_maxqpsize);
#line 238
    wait_any_key();
#line 239
    print_help();
#line 240
    exit(0);
  }
#line 242
  if (learn_parm->svm_maxqpsize < learn_parm->svm_newvarsinqp) {
#line 243
    printf((char const   */* __restrict  */)"\nMaximum size of QP-subproblems [%ld] must be larger than the number of\n",
           learn_parm->svm_maxqpsize);
#line 244
    printf((char const   */* __restrict  */)"new variables [%ld] entering the working set in each iteration.\n",
           learn_parm->svm_newvarsinqp);
#line 245
    wait_any_key();
#line 246
    print_help();
#line 247
    exit(0);
  }
#line 249
  if (learn_parm->svm_iter_to_shrink < 1L) {
#line 250
    printf((char const   */* __restrict  */)"\nMaximum number of iterations for shrinking not in valid range: %ld [1,..]\n",
           learn_parm->svm_iter_to_shrink);
#line 251
    wait_any_key();
#line 252
    print_help();
#line 253
    exit(0);
  }
#line 255
  if (learn_parm->svm_c < (double )0) {
#line 256
    printf((char const   */* __restrict  */)"\nThe C parameter must be greater than zero!\n\n");
#line 257
    wait_any_key();
#line 258
    print_help();
#line 259
    exit(0);
  }
#line 261
  if (learn_parm->transduction_posratio > (double )1) {
#line 262
    printf((char const   */* __restrict  */)"\nThe fraction of unlabeled examples to classify as positives must\n");
#line 263
    printf((char const   */* __restrict  */)"be less than 1.0 !!!\n\n");
#line 264
    wait_any_key();
#line 265
    print_help();
#line 266
    exit(0);
  }
#line 268
  if (learn_parm->svm_costratio <= (double )0) {
#line 269
    printf((char const   */* __restrict  */)"\nThe COSTRATIO parameter must be greater than zero!\n\n");
#line 270
    wait_any_key();
#line 271
    print_help();
#line 272
    exit(0);
  }
#line 274
  if (learn_parm->epsilon_crit <= (double )0) {
#line 275
    printf((char const   */* __restrict  */)"\nThe epsilon parameter must be greater than zero!\n\n");
#line 276
    wait_any_key();
#line 277
    print_help();
#line 278
    exit(0);
  }
#line 280
  if (learn_parm->rho < (double )0) {
#line 281
    printf((char const   */* __restrict  */)"\nThe parameter rho for xi/alpha-estimates and leave-one-out pruning must\n");
#line 282
    printf((char const   */* __restrict  */)"be greater than zero (typically 1.0 or 2.0, see T. Joachims, Estimating the\n");
#line 283
    printf((char const   */* __restrict  */)"Generalization Performance of an SVM Efficiently, ICML, 2000.)!\n\n");
#line 284
    wait_any_key();
#line 285
    print_help();
#line 286
    exit(0);
  }
#line 288
  if (learn_parm->xa_depth < 0L) {
#line 288
    goto _L;
  } else
#line 288
  if (learn_parm->xa_depth > 100L) {
    _L: /* CIL Label */ 
#line 289
    printf((char const   */* __restrict  */)"\nThe parameter depth for ext. xi/alpha-estimates must be in [0..100] (zero\n");
#line 290
    printf((char const   */* __restrict  */)"for switching to the conventional xa/estimates described in T. Joachims,\n");
#line 291
    printf((char const   */* __restrict  */)"Estimating the Generalization Performance of an SVM Efficiently, ICML, 2000.)\n");
#line 292
    wait_any_key();
#line 293
    print_help();
#line 294
    exit(0);
  }
#line 296
  return;
}
}
#line 298 "svm_learn_main.c"
void wait_any_key(void) 
{ 
  struct _IO_FILE **__cil_gp_stdin  = & stdin;
  struct _IO_FILE *__cil_tmp2 ;

  {
  {
#line 300
  printf((char const   */* __restrict  */)"\n(more)\n");
#line 301
  __cil_tmp2 = *__cil_gp_stdin;
#line 301
  _IO_getc(__cil_tmp2);
  }
#line 302
  return;
}
}
#line 304 "svm_learn_main.c"
void print_help(void) 
{ 


  {
  {
#line 306
  printf((char const   */* __restrict  */)"\nSVM-light %s: Support Vector Machine, learning module     %s\n",
         "V6.02", "14.08.08");
#line 307
  copyright_notice();
#line 308
  printf((char const   */* __restrict  */)"   usage: svm_learn [options] example_file model_file\n\n");
#line 309
  printf((char const   */* __restrict  */)"Arguments:\n");
#line 310
  printf((char const   */* __restrict  */)"         example_file-> file with training data\n");
#line 311
  printf((char const   */* __restrict  */)"         model_file  -> file to store learned decision rule in\n");
#line 313
  printf((char const   */* __restrict  */)"General options:\n");
#line 314
  printf((char const   */* __restrict  */)"         -?          -> this help\n");
#line 315
  printf((char const   */* __restrict  */)"         -v [0..3]   -> verbosity level (default 1)\n");
#line 316
  printf((char const   */* __restrict  */)"Learning options:\n");
#line 317
  printf((char const   */* __restrict  */)"         -z {c,r,p}  -> select between classification (c), regression (r),\n");
#line 318
  printf((char const   */* __restrict  */)"                        and preference ranking (p) (default classification)\n");
#line 319
  printf((char const   */* __restrict  */)"         -c float    -> C: trade-off between training error\n");
#line 320
  printf((char const   */* __restrict  */)"                        and margin (default [avg. x*x]^-1)\n");
#line 321
  printf((char const   */* __restrict  */)"         -w [0..]    -> epsilon width of tube for regression\n");
#line 322
  printf((char const   */* __restrict  */)"                        (default 0.1)\n");
#line 323
  printf((char const   */* __restrict  */)"         -j float    -> Cost: cost-factor, by which training errors on\n");
#line 324
  printf((char const   */* __restrict  */)"                        positive examples outweight errors on negative\n");
#line 325
  printf((char const   */* __restrict  */)"                        examples (default 1) (see [4])\n");
#line 326
  printf((char const   */* __restrict  */)"         -b [0,1]    -> use biased hyperplane (i.e. x*w+b>0) instead\n");
#line 327
  printf((char const   */* __restrict  */)"                        of unbiased hyperplane (i.e. x*w>0) (default 1)\n");
#line 328
  printf((char const   */* __restrict  */)"         -i [0,1]    -> remove inconsistent training examples\n");
#line 329
  printf((char const   */* __restrict  */)"                        and retrain (default 0)\n");
#line 330
  printf((char const   */* __restrict  */)"Performance estimation options:\n");
#line 331
  printf((char const   */* __restrict  */)"         -x [0,1]    -> compute leave-one-out estimates (default 0)\n");
#line 332
  printf((char const   */* __restrict  */)"                        (see [5])\n");
#line 333
  printf((char const   */* __restrict  */)"         -o ]0..2]   -> value of rho for XiAlpha-estimator and for pruning\n");
#line 334
  printf((char const   */* __restrict  */)"                        leave-one-out computation (default 1.0) (see [2])\n");
#line 335
  printf((char const   */* __restrict  */)"         -k [0..100] -> search depth for extended XiAlpha-estimator \n");
#line 336
  printf((char const   */* __restrict  */)"                        (default 0)\n");
#line 337
  printf((char const   */* __restrict  */)"Transduction options (see [3]):\n");
#line 338
  printf((char const   */* __restrict  */)"         -p [0..1]   -> fraction of unlabeled examples to be classified\n");
#line 339
  printf((char const   */* __restrict  */)"                        into the positive class (default is the ratio of\n");
#line 340
  printf((char const   */* __restrict  */)"                        positive and negative examples in the training data)\n");
#line 341
  printf((char const   */* __restrict  */)"Kernel options:\n");
#line 342
  printf((char const   */* __restrict  */)"         -t int      -> type of kernel function:\n");
#line 343
  printf((char const   */* __restrict  */)"                        0: linear (default)\n");
#line 344
  printf((char const   */* __restrict  */)"                        1: polynomial (s a*b+c)^d\n");
#line 345
  printf((char const   */* __restrict  */)"                        2: radial basis function exp(-gamma ||a-b||^2)\n");
#line 346
  printf((char const   */* __restrict  */)"                        3: sigmoid tanh(s a*b + c)\n");
#line 347
  printf((char const   */* __restrict  */)"                        4: user defined kernel from kernel.h\n");
#line 348
  printf((char const   */* __restrict  */)"         -d int      -> parameter d in polynomial kernel\n");
#line 349
  printf((char const   */* __restrict  */)"         -g float    -> parameter gamma in rbf kernel\n");
#line 350
  printf((char const   */* __restrict  */)"         -s float    -> parameter s in sigmoid/poly kernel\n");
#line 351
  printf((char const   */* __restrict  */)"         -r float    -> parameter c in sigmoid/poly kernel\n");
#line 352
  printf((char const   */* __restrict  */)"         -u string   -> parameter of user defined kernel\n");
#line 353
  printf((char const   */* __restrict  */)"Optimization options (see [1]):\n");
#line 354
  printf((char const   */* __restrict  */)"         -q [2..]    -> maximum size of QP-subproblems (default 10)\n");
#line 355
  printf((char const   */* __restrict  */)"         -n [2..q]   -> number of new variables entering the working set\n");
#line 356
  printf((char const   */* __restrict  */)"                        in each iteration (default n = q). Set n<q to prevent\n");
#line 357
  printf((char const   */* __restrict  */)"                        zig-zagging.\n");
#line 358
  printf((char const   */* __restrict  */)"         -m [5..]    -> size of cache for kernel evaluations in MB (default 40)\n");
#line 359
  printf((char const   */* __restrict  */)"                        The larger the faster...\n");
#line 360
  printf((char const   */* __restrict  */)"         -e float    -> eps: Allow that error for termination criterion\n");
#line 361
  printf((char const   */* __restrict  */)"                        [y [w*x+b] - 1] >= eps (default 0.001)\n");
#line 362
  printf((char const   */* __restrict  */)"         -y [0,1]    -> restart the optimization from alpha values in file\n");
#line 363
  printf((char const   */* __restrict  */)"                        specified by -a option. (default 0)\n");
#line 364
  printf((char const   */* __restrict  */)"         -h [5..]    -> number of iterations a variable needs to be\n");
#line 365
  printf((char const   */* __restrict  */)"                        optimal before considered for shrinking (default 100)\n");
#line 366
  printf((char const   */* __restrict  */)"         -f [0,1]    -> do final optimality check for variables removed\n");
#line 367
  printf((char const   */* __restrict  */)"                        by shrinking. Although this test is usually \n");
#line 368
  printf((char const   */* __restrict  */)"                        positive, there is no guarantee that the optimum\n");
#line 369
  printf((char const   */* __restrict  */)"                        was found if the test is omitted. (default 1)\n");
#line 370
  printf((char const   */* __restrict  */)"         -y string   -> if option is given, reads alphas from file with given\n");
#line 371
  printf((char const   */* __restrict  */)"                        and uses them as starting point. (default \'disabled\')\n");
#line 372
  printf((char const   */* __restrict  */)"         -# int      -> terminate optimization, if no progress after this\n");
#line 373
  printf((char const   */* __restrict  */)"                        number of iterations. (default 100000)\n");
#line 374
  printf((char const   */* __restrict  */)"Output options:\n");
#line 375
  printf((char const   */* __restrict  */)"         -l string   -> file to write predicted labels of unlabeled\n");
#line 376
  printf((char const   */* __restrict  */)"                        examples into after transductive learning\n");
#line 377
  printf((char const   */* __restrict  */)"         -a string   -> write all alphas to this file after learning\n");
#line 378
  printf((char const   */* __restrict  */)"                        (in the same order as in the training set)\n");
#line 379
  wait_any_key();
#line 380
  printf((char const   */* __restrict  */)"\nMore details in:\n");
#line 381
  printf((char const   */* __restrict  */)"[1] T. Joachims, Making Large-Scale SVM Learning Practical. Advances in\n");
#line 382
  printf((char const   */* __restrict  */)"    Kernel Methods - Support Vector Learning, B. Sch\366lkopf and C. Burges and\n");
#line 383
  printf((char const   */* __restrict  */)"    A. Smola (ed.), MIT Press, 1999.\n");
#line 384
  printf((char const   */* __restrict  */)"[2] T. Joachims, Estimating the Generalization performance of an SVM\n");
#line 385
  printf((char const   */* __restrict  */)"    Efficiently. International Conference on Machine Learning (ICML), 2000.\n");
#line 386
  printf((char const   */* __restrict  */)"[3] T. Joachims, Transductive Inference for Text Classification using Support\n");
#line 387
  printf((char const   */* __restrict  */)"    Vector Machines. International Conference on Machine Learning (ICML),\n");
#line 388
  printf((char const   */* __restrict  */)"    1999.\n");
#line 389
  printf((char const   */* __restrict  */)"[4] K. Morik, P. Brockhausen, and T. Joachims, Combining statistical learning\n");
#line 390
  printf((char const   */* __restrict  */)"    with a knowledge-based approach - A case study in intensive care  \n");
#line 391
  printf((char const   */* __restrict  */)"    monitoring. International Conference on Machine Learning (ICML), 1999.\n");
#line 392
  printf((char const   */* __restrict  */)"[5] T. Joachims, Learning to Classify Text Using Support Vector\n");
#line 393
  printf((char const   */* __restrict  */)"    Machines: Methods, Theory, and Algorithms. Dissertation, Kluwer,\n");
#line 394
  printf((char const   */* __restrict  */)"    2002.\n\n");
  }
#line 395
  return;
}
}
void main_cil_lr_1(DOC ***__cil_ap_docs , double **__cil_ap_target , long totdoc ,
                   long i ) 
{ 
  long i_ssa_1 ;
  int __cil_tmp6 ;
  DOC **__cil_tmp7 ;
  DOC **__cil_tmp8 ;
  DOC *__cil_tmp9 ;

  {
  {
#line 99
  __cil_tmp6 = i < totdoc;
#line 99
  if (__cil_tmp6) {
    {
#line 100
    __cil_tmp7 = *__cil_ap_docs;
#line 100
    __cil_tmp8 = __cil_tmp7 + i;
#line 100
    __cil_tmp9 = *__cil_tmp8;
#line 100
    free_example(__cil_tmp9, 1L);
#line 99
    i_ssa_1 = i + 1L;
    }
    {
    main_cil_lr_1(__cil_ap_docs, __cil_ap_target, totdoc, i_ssa_1);
    }
    return;
  } else {
    return;
  }
  }
}
}
